---
name: Interview Questions Generator
description: Generate structured, behavioral interview questions tailored to specific roles, levels, and competencies.
type: how_to
---

# Interview Questions Generator

## Use Cases

- Preparing for candidate interviews
- Building standardized interview guides for roles
- Training new interviewers on behavioral interviewing
- Ensuring consistent evaluation across candidates
- Creating competency-based assessment frameworks

## Variables

- `[role]`: Job title (e.g., "Senior Product Manager")
- `[level]`: Seniority level (e.g., "Senior / IC5")
- `[competencies]`: Key competencies to assess (e.g., "Strategic thinking, stakeholder management, data-driven decision making, technical acumen")
- `[stage]`: Interview stage (e.g., "Hiring manager round", "Final panel")
- `[time]`: Available time (e.g., "45 minutes")

## Interview Structure

| Section | Time | Focus |
| --------- | ------ | ------- |
| Opening | 5 min | Rapport, background |
| Behavioral | 25 min | Core competencies |
| Situational | 15 min | Judgment, approach |
| Role-Specific | 10 min | Growth PM skills |
| Candidate Q&A | 5 min | Their questions |

## 2. Behavioral Questions (25 minutes)

### Competency 1: Data-Driven Decision Making

**Main Question**:
*"Tell me about a time you had to make a significant product decision with incomplete or conflicting data. How did you approach it?"*

**Follow-up Probes**:

- "What data did you have vs. what did you wish you had?"
- "How did you validate your assumptions?"
- "What would you do differently now?"

**STAR Expectations**:

- **Situation**: Clear business context and stakes
- **Task**: Their specific ownership
- **Action**: Structured approach to synthesis, not just gut feel
- **Result**: Measurable outcome + learnings

### Competency 3: Experimentation Mindset

**Main Question**:
*"Tell me about an experiment you ran that failed. What did you learn, and how did it influence your next steps?"*

**Follow-up Probes**:

- "How did you decide what to test in the first place?"
- "How did you communicate the failure to stakeholders?"
- "What did you do with the learnings?"

**STAR Expectations**:

- Embraces failure as learning (not defensive)
- Has a rigorous experimentation framework
- Can articulate statistical significance, sample sizes

### Competency 5: Strategic Thinking

**Main Question**:
*"Tell me about a time you identified a growth opportunity that wasn't on anyone's roadmap. How did you build the case for it?"*

**Follow-up Probes**:

- "How big was the opportunity vs. current priorities?"
- "What tradeoffs did you have to make?"
- "How did you sequence the rollout?"

**STAR Expectations**:

- Thinks beyond current sprint/quarter
- Can quantify opportunity size
- Balances vision with pragmatic execution

### Scenario 2: Experiment Design

*"You're tasked with improving our onboarding flow. Activation rate is 34% (new users who complete setup within 7 days). You have 4 weeks and one engineer. Walk me through how you'd approach this."*

**What to assess**:

- Structured thinking (diagnose before prescribe)
- Experimentation rigor
- Scrappiness within constraints

**Great answer includes**: Starts with data/funnel analysis, talks to churned users, prioritizes highest-leverage tests, acknowledges what they'd do with more resources

## 4. Role-Specific Questions (10 minutes)

### Growth PM Technical Skills

**Q1: Metrics**
*"How would you structure the metrics for a growth team? What's your North Star vs. supporting metrics?"*

**Listen for**: Understands leading vs. lagging indicators, can articulate funnel stages, doesn't obsess over vanity metrics

**Q2: Tooling**
*"What's your experience with experimentation platforms and analytics tools? Walk me through your typical workflow for launching and analyzing an experiment."*

**Listen for**: Hands-on with Amplitude/Mixpanel, understands statistical significance, can configure experiments independently

**Q3: Growth Levers**
*"If you joined our Growth team next month, what's the first thing you'd want to understand about our acquisition and activation funnels?"*

**Listen for**: Asks smart questions (not generic), prioritizes understanding before acting, shows genuine curiosity

## 6. Scoring Rubric

| Competency | Strong (4-5) | Adequate (3) | Concerning (1-2) |
| ------------ | -------------- | -------------- | ------------------ |
| **Data-Driven** | Cites specific metrics, acknowledges data limitations, makes probabilistic decisions | Uses data but can't explain methodology deeply | Relies on intuition, can't articulate how they'd measure success |
| **Cross-Functional** | Concrete examples of building consensus, shows empathy for other teams | Has collaborated but waited for decisions to come to them | Blames other teams, sees alignment as someone else's job |
| **Experimentation** | Can design rigorous experiments, embraces failures, iterates based on learnings | Has run experiments but didn't own the analysis | Hasn't run real experiments or sees them as "nice to have" |
| **Customer Empathy** | Direct customer contact, synthesizes qual + quant, changed their own mind | Reads user research but doesn't conduct it | Views customers as abstract personas, not real people |
| **Strategic** | Identifies opportunities independently, can size and sequence, thinks in quarters not sprints | Executes strategy given to them well | Focuses only on immediate tasks, no long-term view |

## Tips

- Ask the same core questions to every candidate for fair comparison
- Use follow-up probes to get past rehearsed answers
- Listen for specific examples with measurable results, not hypotheticals
- Take notes on exact quotes - they're more useful than your interpretations
- Leave time for candidate questions - how they ask reveals a lot

---

## Related Prompts

- [job-description-writer](./job-description-writer.md) - For creating the job posting
- [performance-review](./performance-review.md) - For evaluating employees post-hire
- [onboarding-checklist-creator](./onboarding-checklist-creator.md) - For successful new hire starts
