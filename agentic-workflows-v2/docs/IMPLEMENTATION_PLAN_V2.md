# Implementation Plan v2 - Migration & Module Expansion

**Status:** âœ… PHASE 2D COMPLETE  
**Created:** February 3, 2026  
**Updated:** February 4, 2026  
**Based On:** Industry Architecture Research (AutoGen, LangGraph, CrewAI, OpenAI Agents SDK, MS Agent Framework)

### Progress Summary

- **Tests:** 370+ passing (as of Feb 4, 2026)
- **Agents:** ArchitectAgent, TestAgent migrated
- **Prompts:** 13 templates migrated with loader utility
- **Configs:** agents.yaml, models.yaml, evaluation.yaml migrated
- **Workflows:** 3 definitions in place
- **Tools:** 5 new tool categories added (Git, HTTP, Shell, CodeAnalysis, Search)
- **Memory/Context:** Token-aware `ConversationMemory` + persistent memory/context builtin tools

---

## ğŸ“‹ Overview

This plan covers migrating missing components from the original `multiagent-workflows/` source and establishing the final module architecture based on industry best practices.

### Architecture Decision Summary

| Decision | Rationale |
|----------|-----------|
| **Agents + Workflows = Same Package** | Industry consensus - tightly coupled |
| **Evaluation = Separate Package** | Optional, different dependencies |
| **Server = Optional Install** | `pip install agentic-v2[server]` |
| **Tools = Same Package** | Core functionality needed |
| **Tests = Same Repo** | Standard Python convention |

---

## ğŸ¯ Phase 2A: Component Migration (From Original Source)

### Priority 1: Missing Agents

| Agent | Source | Target | Status |
|-------|--------|--------|--------|
| `ArchitectAgent` | `multiagent-workflows/src/.../agents/architect_agent.py` | `agentic_v2/agents/architect.py` | âœ… Done |
| `TestAgent` | `multiagent-workflows/src/.../agents/test_agent.py` | `agentic_v2/agents/test_agent.py` | âœ… Done |

> **Tests:** 36 new tests added in `tests/test_new_agents.py` - All passing (341 total)

### Priority 2: Prompt Templates (13 files)

> **Status: âœ… COMPLETE** - 13 prompts migrated with loader utility

| Prompt | Source | Target | Status |
|--------|--------|--------|--------|
| `analyst.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `architect.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `coder.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `debugger.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `judge.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `planner.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `reasoner.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `researcher.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `reviewer.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `tester.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `validator.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `vision.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |
| `writer.md` | `multiagent-workflows/config/prompts/` | `agentic_v2/prompts/` | âœ… Done |

**Utilities Added:**

- `prompts/__init__.py` with `load_prompt()`, `list_prompts()`, `get_prompt_path()`
- Prompt name constants for autocompletion

### Priority 3: Workflow Definitions (5 files)

> **Status: âœ… PARTIAL** - 3 workflows in place, configs migrated

| Workflow | Description | Status |
|----------|-------------|--------|
| `code_review.yaml` | Code review workflow | âœ… Already exists |
| `fullstack_generation.yaml` | Full development cycle | âœ… Already exists |
| `plan_implementation.yaml` | Iterative implementation workflow | âœ… Migrated |

### Priority 4: Configuration Files

> **Status: âœ… COMPLETE**

| Config | Description | Status |
|--------|-------------|--------|
| `agents.yaml` | Agent definitions | âœ… Migrated to `config/defaults/` |
| `models.yaml` | Model configurations | âœ… Migrated to `config/defaults/` |
| `evaluation.yaml` | Evaluation settings | âœ… Migrated to `config/defaults/` |

---

## ğŸ¯ Phase 2B: Evaluation Module (Separate Package)

Based on industry patterns, evaluation should be a **separate optional package**.

### Structure: `agentic-v2-eval/`

```
agentic-v2-eval/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ src/agentic_v2_eval/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scorer.py           # Scoring framework
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ accuracy.py     # Accuracy metrics
â”‚   â”‚   â”œâ”€â”€ quality.py      # Code quality metrics
â”‚   â”‚   â””â”€â”€ performance.py  # Execution metrics
â”‚   â”œâ”€â”€ rubrics/
â”‚   â”‚   â””â”€â”€ default.yaml    # Evaluation rubrics
â”‚   â”œâ”€â”€ runners/
â”‚   â”‚   â”œâ”€â”€ batch.py        # Batch evaluation runner
â”‚   â”‚   â””â”€â”€ streaming.py    # Streaming evaluation
â”‚   â””â”€â”€ reporters/
â”‚       â”œâ”€â”€ json.py         # JSON output
â”‚       â”œâ”€â”€ markdown.py     # Markdown reports
â”‚       â””â”€â”€ html.py         # HTML dashboards
â””â”€â”€ tests/
    â””â”€â”€ test_eval.py
```

| Component | Description | Status |
|-----------|-------------|--------|
| Scorer Framework | Port from original `evaluation/scorer.py` | â¬œ Todo |
| Rubric System | YAML-based evaluation rubrics | â¬œ Todo |
| Batch Runner | Run evals across test datasets | â¬œ Todo |
| Reporters | JSON, Markdown, HTML output | â¬œ Todo |

---

## ğŸ¯ Phase 2C: Server Module (Optional Install)

### Option 1: Install Extra (Recommended)

Add to `pyproject.toml`:

```toml
[project.optional-dependencies]
server = [
    "fastapi>=0.100.0",
    "uvicorn>=0.23.0",
    "websockets>=11.0",
]
```

### Structure: `agentic_v2/server/`

```
src/agentic_v2/server/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ app.py              # FastAPI application
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ workflows.py    # Workflow endpoints
â”‚   â”œâ”€â”€ agents.py       # Agent endpoints
â”‚   â””â”€â”€ health.py       # Health checks
â”œâ”€â”€ models.py           # API request/response models
â””â”€â”€ websocket.py        # Real-time streaming
```

| Component | Description | Status |
|-----------|-------------|--------|
| FastAPI App | REST API for workflows | âœ… Done |
| Workflow Routes | Execute/list/validate workflows | âœ… Done |
| Agent Routes | Run agents, get capabilities | âœ… Done |
| WebSocket | Real-time execution streaming | âœ… Done |

---

## ğŸ¯ Phase 2D: Enhanced Tools

### Additional Builtin Tools

| Tool | Description | Tier | Status |
|------|-------------|------|--------|
| `GitTool` | Git operations (status, diff, commit) | 0 | âœ… Done |
| `HttpTool` | HTTP requests (GET, POST, etc.) | 0 | âœ… Done |
| `ShellTool` | Execute shell commands | 0 | âœ… Done |
| `CodeAnalysisTool` | AST parsing, complexity | 1 | âœ… Done |
| `SearchTool` | Semantic search in files | 2 | âœ… Done |

**Implementation Details:**

- **Git Operations** (`git_ops.py`):
  - `GitTool`: Main tool with support for status, diff, log, add, commit, branch commands
  - `GitStatusTool`: Convenience wrapper for git status
  - `GitDiffTool`: Convenience wrapper for git diff
  
- **HTTP Operations** (`http_ops.py`):
  - `HttpTool`: Full HTTP client with GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS
  - `HttpGetTool`: Convenience wrapper for GET requests
  - `HttpPostTool`: Convenience wrapper for POST requests with JSON body
  
- **Shell Execution** (`shell_ops.py`):
  - `ShellTool`: Execute shell commands with security controls (blocks dangerous operations)
  - `ShellExecTool`: Execute commands with automatic argument escaping
  
- **Code Analysis** (`code_analysis.py`):
  - `CodeAnalysisTool`: Analyze Python code for metrics (lines, functions, classes, imports, complexity)
  - `AstDumpTool`: Generate AST dumps for detailed structure analysis
  
- **Search Operations** (`search_ops.py`):
  - `SearchTool`: Multi-mode search (regex, fuzzy, semantic) with recursive directory support
  - `GrepTool`: Quick grep-like pattern matching

**Test Coverage:** 28 new tests covering all tools and edge cases (100% pass rate)

---

## ğŸ§  Post-2D: Memory & Context Utilities

While working through Phase 2D, we also hardened the agent memory and added deterministic context helpers.

- **Token-aware conversation memory:** `ConversationMemory` now trims to a *message budget* and an *approximate token budget* (`AgentConfig.max_memory_messages`, `AgentConfig.max_memory_tokens`).
- **Persistent memory tools:** Built-in CRUD tools backed by a JSON file.
  - Configure the storage location with `AGENTIC_MEMORY_PATH`.
- **Context utilities:** `token_estimate` + `context_trim` helpers for predictable context shaping.

---

## ğŸ¯ Phase 2E: Documentation & Polish

| Task | Description | Status |
|------|-------------|--------|
| API Reference | Auto-generated from docstrings | âœ… Done |
| Tutorials | Step-by-step guides (kept in sync with public API) | ğŸš§ In progress |
| README | Quick start + current CLI/Python examples | ğŸš§ In progress |
| Examples | Real-world usage examples | âœ… Done |
| Architecture Docs | ADRs, design decisions | âœ… Done |

---

## ğŸ“Š Progress Tracker

### Phase 2A: Migration

- [ ] Architect Agent
- [ ] Test Agent  
- [ ] 13 Prompt Templates
- [ ] 5 Workflow Definitions
- [ ] 3 Config Files

### Phase 2B: Evaluation Package

- [ ] Project structure
- [ ] Scorer framework
- [ ] Rubric system
- [ ] Reporters

### Phase 2C: Server Module

- [x] FastAPI integration
- [x] Workflow routes
- [x] WebSocket streaming

### Phase 2D: Tools

- [x] Git operations
- [x] HTTP requests
- [x] Shell execution

### Phase 2E: Documentation

- [x] API reference
- [x] Tutorials
- [x] Examples

---

## ğŸ” Refinement: Issues & Ideas Assessment (Feb 4, 2026)

Critical review of the evaluation migration plan identified duplications and coupling risks.

### Identified Issues

1. **Three overlapping Scorers**: `tools/prompteval/unified_scorer`, `multiagent-workflows/.../scorer`, and `agentic-v2-eval/scorer` have conflicting interfaces.
2. **LLMClientProtocol mismatch**: `llm.py` defines a protocol, but `agentic-workflows-v2` uses a different client structure.
3. **Sandbox is Docker-only**: Blocks local development; need `LocalSubprocessSandbox`.
4. **Benchmark code stranded**: Code remains in `tools/agents/benchmarks`, creating import risks.
5. **No tests for loader**: Benchmark loader lacks unit tests.
6. **Pattern scorer coupled**: Tightly coupled to `tools.llm.llm_client`.
7. **Rubrics external**: Depends on files in `rubrics/` outside the package.
8. **No CI**: Evaluation tests not in CI.

### Refined Prioritization

| Priority | Task | Rationale |
|----------|------|-----------|
| **P0** | **Sandbox (Local)** | Unblocks dev execution. |
| **P0** | **Benchmark Tests** | Ensures data reliability. |
| **P1** | **LLM Protocol** | Unifies model access. |
| **P1** | **Move Benchmarks** | Fixes architecture/imports. |
| **P2** | **Merge Scorers** | Unified Scoring API. |
| **P2** | **Decouple Pattern Scorer** | Clean dependencies. |
| **P3** | **Rubrics/CI** | Polish/Integration. |

> **Current Focus:** Implementing **P2** (Merge Scorers & Decouple Pattern Scorer) as requested.

---

## ğŸ—ï¸ Target Architecture (Post-Phase 2)

```
agentic-workflows-v2/
â”œâ”€â”€ src/agentic_v2/           # Main package
â”‚   â”œâ”€â”€ agents/               # All agents (7+)
â”‚   â”œâ”€â”€ cli/                  # CLI commands
â”‚   â”œâ”€â”€ config/               # YAML configs
â”‚   â”œâ”€â”€ contracts/            # Pydantic schemas
â”‚   â”œâ”€â”€ engine/               # DAG execution
â”‚   â”œâ”€â”€ models/               # LLM routing
â”‚   â”œâ”€â”€ prompts/              # Agent prompts (13+)
â”‚   â”œâ”€â”€ server/               # Optional REST API
â”‚   â”œâ”€â”€ tools/                # Builtin tools (18+)
â”‚   â””â”€â”€ workflows/            # Definitions (7+)
â”œâ”€â”€ tests/                    # ~350+ tests
â”œâ”€â”€ pyproject.toml            # With [server], [dev] extras
â””â”€â”€ README.md

# Separate Package (Optional)
agentic-v2-eval/              # Evaluation framework
â”œâ”€â”€ src/agentic_v2_eval/
â””â”€â”€ tests/
```

---

## ğŸ“ˆ Success Metrics

| Metric | Current | Target |
|--------|---------|--------|
| Tests | 369 | 400+ |
| Agents | 4 | 7+ |
| Workflows | 2 | 7+ |
| Tools | 18 | 18+ âœ… |
| Prompts | 0 | 13+ |
| Documentation | Basic | Full API docs |

---

## ğŸ”— References

- [AutoGen Architecture](https://github.com/microsoft/autogen) - Layered packages
- [LangGraph](https://github.com/langchain-ai/langgraph) - Graph-based workflows
- [CrewAI](https://github.com/crewAIInc/crewAI) - Crews + Flows pattern
- [OpenAI Agents SDK](https://github.com/openai/openai-agents-python) - Minimal core
- [MS Agent Framework](https://github.com/microsoft/agent-framework) - Multi-package mono-repo

---

**Next Action:** Start with Phase 2A Priority 1 (Missing Agents)
