# ADR-007: Multidimensional Classification Matrix and Stop Policy for Iterative Deep Research

---

| Field        | Value |
|--------------|-------|
| **ID**       | ADR-007 |
| **Status**   | ğŸŸ¡ Proposed |
| **Date**     | 2026-02-23 |
| **System**   | agentic-workflows-v2 Â· deep-research pipeline |
| **Authors**  | Platform Engineering |
| **Reviewers**| Research Infra, ML Platform |
| **Supersedes** | _(none)_ |

---

## 1. TL;DR

> **We abandon the single weighted "Confidence Index" scalar as the gate for stopping iterative research rounds. Instead, we adopt a DORA-style multidimensional classification matrix where every dimension must independently achieve "High" or better before stopping. The CI scalar is retained only as a tiebreaker for the `coalesce()` best-of-N selector.**

---

## 2. Status History

| Date | Status | Note |
|------|--------|------|
| 2026-02-10 | ğŸ”µ Draft | Initial CI-weighted-sum proposal |
| 2026-02-18 | ğŸŸ  Under Review | Challenge: compensability masks single-dimension failures |
| 2026-02-23 | ğŸŸ¡ Proposed | Pivoted to multidimensional matrix; CI demoted to tiebreaker |

---

## 3. Context & Problem Statement

The **agentic-workflows-v2** system runs a **10-node deep research pipeline** with bounded iterative rounds R1â€“R4. Each round produces a research artifact. The system must answer three questions before committing to a round result or continuing:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           THREE QUESTIONS THE STOP POLICY MUST ANSWER         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Q1 â”‚ How should multi-dimensional research quality be scored? â”‚
â”‚  Q2 â”‚ When should iterative refinement stop?                   â”‚
â”‚  Q3 â”‚ How should source temporal freshness factor in?          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.1 Pipeline Architecture

```mermaid
flowchart LR
    subgraph PIPELINE ["ğŸ”¬ Deep Research Pipeline (R1â€“R4)"]
        direction LR
        R1["Round 1\nResearch Artifact"] -->|score| E1{Gate?}
        E1 -->|PASS| C["coalesce()\nbest-of-N"]
        E1 -->|FAIL| R2["Round 2\nRefined Artifact"]
        R2 -->|score| E2{Gate?}
        E2 -->|PASS| C
        E2 -->|FAIL| R3["Round 3"]
        R3 -->|score| E3{Gate?}
        E3 -->|PASS| C
        E3 -->|FAIL| R4["Round 4\n(Max)"]
        R4 -->|score| C
    end
    C --> OUT["âœ… Final Output"]
```

### 3.2 Why the Original CI Formula Failed

The original proposal was a **weighted arithmetic mean (WAM)**:

> **CI = 0.25 Ã— coverage + 0.20 Ã— source_quality + 0.20 Ã— agreement + 0.20 Ã— verification + 0.15 Ã— recency**
>
> _Stop when: CI â‰¥ 0.80 AND recent_sources_count â‰¥ 10 AND critical_contradictions == 0_

**The compensability problem** â€” a WAM lets high scores in one dimension mask failure in another:

| Scenario | Coverage | Verification | Recency | **WAM Result** | **Actual Quality** |
|----------|----------|--------------|---------|----------------|--------------------|
| Nominal | 0.90 | 0.85 | 0.80 | **0.87** âœ… | Good |
| Masked failure | 0.95 | **0.20** | 0.95 | **0.67** âœ… | âŒ Dangerous |
| True failure | 0.40 | 0.40 | 0.40 | **0.40** âŒ | Correctly caught |

> A verification score of 0.20 represents unverified claims â€” yet the WAM returns a passing score of 0.67. The single composite number hides the failure.

---

## 4. Decision

> **Adopt a DORA-style multidimensional classification matrix as the primary stop gate. Demote the CI weighted sum to a secondary tiebreaker role only.**

### 4.1 The Multidimensional Classification Matrix

Each research dimension is independently scored into one of four performance tiers:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          RESEARCH QUALITY CLASSIFICATION MATRIX                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•£
â•‘ Tier     â•‘ Coverage  â•‘ Src Qualityâ•‘ Agreement â•‘Verificationâ•‘Rec.â•‘
â• â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•£
â•‘ ğŸ† Elite â•‘  â‰¥ 0.90   â•‘  â‰¥ 0.90   â•‘  â‰¥ 0.90   â•‘  â‰¥ 0.90   â•‘â‰¥90dâ•‘
â•‘ âœ… High  â•‘  â‰¥ 0.75   â•‘  â‰¥ 0.75   â•‘  â‰¥ 0.75   â•‘  â‰¥ 0.75   â•‘â‰¥60dâ•‘
â•‘ âš ï¸ Mediumâ•‘  â‰¥ 0.50   â•‘  â‰¥ 0.50   â•‘  â‰¥ 0.50   â•‘  â‰¥ 0.50   â•‘â‰¥30dâ•‘
â•‘ âŒ Low   â•‘  < 0.50   â•‘  < 0.50   â•‘  < 0.50   â•‘  < 0.50   â•‘<30dâ•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•
```

> **Dimension definitions:**
>
> - **Coverage** â€” breadth of topics addressed relative to the query scope
> - **Source Quality** â€” authority, peer-review status, and citation depth of sources
> - **Agreement** â€” cross-source corroboration; absence of contradicting claims
> - **Verification** â€” active fact-checking and claim provenance tracing
> - **Recency** â€” proportion of sources published within the domain-adaptive window

### 4.2 Stop Gate Logic

```mermaid
flowchart TD
    GS["ğŸ“Š Score All 5 Dimensions"]
    GS --> CK1{"All dimensions\nâ‰¥ High?"}
    CK1 -->|No| CK1F["âŒ CONTINUE\nto next round"]
    CK1 -->|Yes| CK2{"recent_sources_count\nâ‰¥ 10?"}
    CK2 -->|No| CK2F["âŒ CONTINUE\nto next round"]
    CK2 -->|Yes| CK3{"critical_contradictions\n== 0?"}
    CK3 -->|No| CK3F["ğŸ›‘ HALT (contradiction)\ncoalesce() selects best prior round"]
    CK3 -->|Yes| PASS["âœ… STOP\nThis round passes"]

    CK1F --> REG{"Consecutive\nregression\ndetected?"}
    CK2F --> REG
    REG -->|Yes| STOP2["ğŸ›‘ PATIENCE STOP\ncoalesce() selects best round"]
    REG -->|No| NEXT["â–¶ Next Round"]
```

**Stopping conditions (formal):**

| Condition | Type | Trigger |
|-----------|------|---------|
| All dimensions â‰¥ High | Non-compensatory conjunction | Primary pass gate |
| recent_sources_count â‰¥ 10 | Hard floor | Minimum evidence gate |
| critical_contradictions == 0 | Veto override | Single disqualifier |
| Consecutive regression (patience = 1) | ML early stopping | Performance degradation |
| Round R4 reached | Hard bound | Max iteration guard |

### 4.3 Best-of-N Tiebreaker (CI as Secondary Scorer)

When `coalesce()` must rank multiple passing rounds â€” or select the "least bad" round when all fail â€” the CI weighted sum is used **only at this step**:

```
CI (tiebreaker) = 0.25 Ã— coverage
                + 0.20 Ã— source_quality
                + 0.20 Ã— agreement
                + 0.20 Ã— verification
                + 0.15 Ã— recency
```

> âš ï¸ **This weight vector has no empirical calibration.** See Â§7 (Open Questions) for sensitivity analysis requirements.

**Alternative tiebreaker weight candidates:**

| Weight Strategy | Coverage | Src Quality | Agreement | Verification | Recency | Basis |
|-----------------|----------|-------------|-----------|--------------|---------|-------|
| Proposed | 0.25 | 0.20 | 0.20 | 0.20 | 0.15 | Intuitive ranking |
| Equal weights | 0.20 | 0.20 | 0.20 | 0.20 | 0.20 | Dawes (1979) |
| ROC weights | **0.46** | 0.21 | 0.21 | 0.21 | **0.11** | Barron & Barrett (1996) |

---

## 5. Rationale

### 5.1 Production Precedents for Multidimensional Gates

| System | Approach | Compensatory? | Analog in This ADR |
|--------|----------|---------------|--------------------|
| **DORA Metrics** | Elite/High/Medium/Low per dimension; no aggregate | âŒ No | Direct inspiration for tier model |
| **SonarQube** | Conjunctive A-ratings; any failure = overall FAIL | âŒ No | `critical_contradictions == 0` veto |
| **Google SRE Error Budget** | Binary gate; budget exhaustion halts all changes | âŒ No | Hard floor constraints |
| **Dynatrace Quality Gates** | key_SLI flag creates hard non-compensatory gate | âŒ No (for key SLIs) | Dimension-level "veto" semantics |
| **OpenAI Evals** | Per-metric scores; no built-in composite | âŒ No | Per-dimension reporting |
| **Stanford HELM** | Equal-weighted composite (abandoned) | âœ… Yes (original) | âš ï¸ Counter-example â€” HELM moved away |

### 5.2 Compensability Danger Illustrated

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  "The Masking Problem" â€” WAM Hides Catastrophic Failure  â”‚
â”‚                                                         â”‚
â”‚  Coverage      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  0.95              â”‚
â”‚  Src Quality   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  0.95              â”‚
â”‚  Agreement     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  0.90              â”‚
â”‚  Verification  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.20  â† FAILURE  â”‚
â”‚  Recency       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  0.95              â”‚
â”‚                                            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  WAM Result:   0.79  âœ… (PASSES old CI gate!)          â”‚
â”‚  Matrix Gate:  âŒ FAIL  (Verification = Low)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.3 Iterative Refinement Degradation â€” Why Bounds Matter

LLM iterative self-improvement has **empirically established limits**:

```mermaid
xychart-beta
    title "Quality vs. Refinement Round (SELF-REFINE empirical pattern)"
    x-axis ["R1", "R2", "R3", "R4", "R5"]
    y-axis "Relative Quality" 0 --> 130
    line [85, 105, 117, 119, 112]
```

| Research | Finding | Implication |
|----------|---------|-------------|
| SELF-REFINE (NeurIPS 2023) | Quality plateaus by round 3â€“4 | R1â€“R4 bound is empirically justified |
| Huang et al. (ICLR 2024) | Without external feedback, self-correction degrades | Consecutive-regression stop is necessary |
| Snell et al. (2024) | 38% of revisions corrupt correct answers | `coalesce()` best-of-N is required, not optional |
| Gao, Schulman & Hilton (ICML 2023) | BON degrades past Nâ‰ˆ16 under proxy scoring | 4-round bound is safely within optimum |

### 5.4 Recency â€” Why 183 Days Is Wrong

The prior 183-day freshness window was borrowed from **international tax residency law** (IRS Substantial Presence Test), not information retrieval. It has no IR basis.

**Domain-adaptive window targets (to replace 183-day hard cutoff):**

| Domain | Recommended Freshness Window | Rationale |
|--------|------------------------------|-----------|
| Current events / politics | 7â€“30 days | High publication velocity |
| Technology releases | 30â€“90 days | Rapid version churn |
| Academic research surveys | 12â€“24 months | Peer review cycle |
| Foundational science | Recency not required | Timeless literature |
| Financial market data | Hoursâ€“days | Real-time decay |

> **Decision:** Replace the fixed 183-day window with a **domain-adaptive freshness classifier** that infers the appropriate window from source publication rate (following the Google QDF model).

---

## 6. Consequences

### 6.1 Positive Outcomes

| Outcome | Mechanism |
|---------|-----------|
| No more masked failures | Non-compensatory conjunction; one Low blocks the gate |
| Aligns with industry direction | DORA, OpenAI Evals, HELM all moved to per-dimension reporting |
| Empirically bounded iterations | R1â€“R4 cap validated by SELF-REFINE & BON overoptimization research |
| Scores are interpretable | Each dimension has a clear tier; no opaque composite |

### 6.2 Trade-offs and Risks

| Risk | Severity | Mitigation |
|------|----------|------------|
| CI tiebreaker weights are uncalibrated | ğŸŸ  Medium | Sensitivity analysis (Â§7) before deployment |
| Recency tier thresholds are provisional | ğŸŸ  Medium | Domain-adaptive window per Â§5.4 |
| All-fail scenarios need fallback | ğŸŸ¡ Low | `coalesce()` selects lowest-CI "least bad" round |
| No confidence intervals on tier scores | ğŸŸ¡ Low | Follow Anthropic "Adding Error Bars" guidance |
| `recent_sources_count â‰¥ 10` floor is arbitrary | ğŸŸ¡ Low | Validate against corpus quality benchmarks |

---

## 7. Open Questions & Required Actions

| # | Action | Owner | Priority | Deadline |
|---|--------|-------|----------|----------|
| 1 | Sensitivity analysis: test Proposed vs. Equal vs. ROC tiebreaker weights on historical pipeline outputs | Research Infra | ğŸ”´ P1 | Before prod |
| 2 | Implement domain-adaptive recency window; replace 183-day hard cutoff | Platform Eng | ğŸ”´ P1 | Before prod |
| 3 | Add confidence intervals to dimension tier classifications | ML Platform | ğŸŸ  P2 | Sprint +1 |
| 4 | Validate `recent_sources_count â‰¥ 10` floor against corpus size benchmarks | Research Infra | ğŸŸ  P2 | Sprint +2 |
| 5 | Difficulty-adaptive thresholds: consider varying "High" bar by query complexity | Research | ğŸŸ¡ P3 | Backlog |

---

## 8. Alternatives Considered

| Alternative | Description | Rejected Because |
|-------------|-------------|-----------------|
| **Weighted CI as primary gate** (prior design) | WAM of 5 dimensions with 0.80 threshold | Compensability masks catastrophic single-dimension failures |
| **Geometric mean** | Partial compensability penalty | Double-penalizes low scores alongside explicit floor gates; over-penalizes |
| **Pure minimum (SonarQube-strict)** | Gate = `min(all dimensions) â‰¥ 0.75` | Too brittle; single noisy dimension could permanently stall pipeline |
| **No composite, conjunct-only** | Report tier vector; no CI tiebreaker at all | `coalesce()` requires a scalar to rank candidates; cannot avoid |

---

## 9. References

| Citation | Relevance |
|----------|-----------|
| DORA State of DevOps 2024 | Foundation for multidimensional tier model |
| Madaan et al. â€” SELF-REFINE (NeurIPS 2023) | Validates R1â€“R4 iteration bound |
| Huang et al. (ICLR 2024) | Demonstrates intrinsic self-correction degradation |
| Snell et al. (2024) â€” Sequential Revision Models | Motivates `coalesce()` best-of-N over final-round selection |
| Gao, Schulman & Hilton (ICML 2023) | BON overoptimization scaling laws; validates 4-round bound |
| Dawes (1979) â€” Robust Beauty of Improper Models | Equal-weight baseline for tiebreaker |
| Barron & Barrett (1996) â€” ROC Weights | ROC weight alternative for tiebreaker |
| Prechelt (1998) â€” Early Stopping | Patience-based stopping; maps to consecutive-regression mechanism |
| Barbaresi (2020) â€” htmldate (JOSS) | Date extraction reliability limits |
| Anthropic â€” Adding Error Bars to Evals (2024) | Confidence interval guidance |

---

## 10. Decision Record Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ADR-007 DECISION MAP                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  OLD:  One CI score â”€â”€â†’ threshold gate â”€â”€â†’ stop/continue â”‚
â”‚                                                          â”‚
â”‚  NEW:  5 Dimensions â”€â”€â†’ each classified independently    â”‚
â”‚             â”‚                                            â”‚
â”‚             â”œâ”€â”€ All â‰¥ High? â”€â”€â†’ AND â”€â”€â†’ sources â‰¥ 10?   â”‚
â”‚             â”‚                    AND â”€â”€â†’ contradictions=0â”‚
â”‚             â”‚                     â”‚                     â”‚
â”‚             â”‚                  STOP âœ…                   â”‚
â”‚             â”‚                                            â”‚
â”‚             â””â”€â”€ Any < High? â”€â”€â†’ CONTINUE or PATIENCE     â”‚
â”‚                                    STOP after regression â”‚
â”‚                                                          â”‚
â”‚  coalesce(): CI score used ONLY to rank candidates       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **Approved by:** _(pending review)_
> **Next review date:** 2026-03-23
