---
title: Prompt Engineering Glossary
shortTitle: Glossary
intro: Definitions of key terms and concepts used in prompt engineering.
type: reference
difficulty: beginner
audience:

  - junior-engineer
  - senior-engineer
  - solution-architect
  - business-analyst
  - project-manager

platforms:

  - github-copilot
  - claude
  - chatgpt
  - azure-openai
  - m365-copilot

topics:

  - fundamentals
  - terminology

author: Prompt Library Team
version: '1.0'
date: '2025-12-02'
governance_tags:

  - PII-safe

dataClassification: public
reviewStatus: approved
---

# Prompt Engineering Glossary

Definitions of key terms and concepts used in prompt engineering and AI interactions.

---

## A

### Agent / Agentic AI
An AI system that can take autonomous actions, make decisions, and use tools to accomplish tasks. Unlike simple chat interfaces, agents can plan multi-step workflows and interact with external systems.

**Example:** An AI agent that can search the web, write code, run tests, and commit changes to a repository.

### Alignment
The process of ensuring AI systems behave according to human intentions and values. Aligned models follow instructions accurately and avoid harmful outputs.

### API (Application Programming Interface)
A way to programmatically interact with AI services. APIs allow developers to send prompts and receive responses in their applications.

### Attention
The mechanism in transformer models that allows the model to focus on relevant parts of the input when generating each part of the output. More attention = more influence on the output.

---

## C

### Chain-of-Thought (CoT)
A prompting technique that asks the model to show its reasoning step by step before providing a final answer. Improves accuracy on complex reasoning tasks.

**Example:** "Think through this step by step before giving your answer."

### Completion
The output generated by a language model in response to a prompt. Also called a "response" or "generation."

### Context Window
The maximum amount of text (measured in tokens) that a model can process at once, including both the prompt and the response. Larger context windows allow for longer documents and conversations.

| Model | Context Window |
| ------- | ---------------- |
| GPT-3.5 | 4K-16K tokens |
| GPT-4 | 8K-128K tokens |
| Claude 3 | 200K tokens |

### Constitutional AI
An AI training approach (used by Anthropic) where the model is trained to follow a set of principles ("constitution") that guide its behavior.

---

## E

### Embedding
A numerical representation of text as a vector (list of numbers). Embeddings capture semantic meaning, allowing for similarity comparisons between texts.

**Use case:** Finding similar documents, semantic search, clustering content.

### Emergent Behavior
Capabilities that appear in larger models that weren't explicitly trained for and weren't present in smaller models. Examples include chain-of-thought reasoning and in-context learning.

---

## F

### Few-Shot Learning
A prompting technique where you provide a few examples of the desired input-output pattern before the actual task. The model learns the pattern from these examples.

**Example:**

```yaml
Input: dog
Output: animal

Input: rose
Output: flower

Input: car
Output:
```text

### Fine-Tuning
The process of further training a pre-trained model on specific data to specialize it for particular tasks or domains. Results in a customized model.

### Function Calling
A capability that allows language models to generate structured outputs that trigger specific functions or APIs. Used in agentic applications.

---

## G

### Grounding
Connecting AI responses to factual, verifiable sources. Grounded responses include references to source material and are less likely to contain hallucinations.

### Guardrails
Safety mechanisms that prevent AI systems from generating harmful, inappropriate, or off-topic content. Can be implemented in prompts, system settings, or additional filtering layers.

---

## H

### Hallucination
When an AI generates information that is factually incorrect, made up, or not supported by its training data. Models may "hallucinate" fake citations, incorrect facts, or non-existent features.

**Mitigation:** Ask for sources, verify claims, use RAG for grounding.

---

## I

### In-Context Learning
The ability of language models to learn new tasks from examples provided in the prompt, without any additional training. This is how few-shot learning works.

### Inference
The process of generating a response from a trained model. When you send a prompt, the model performs inference to produce the completion.

### Instruction Tuning
Training a model to follow natural language instructions. Instruction-tuned models (like GPT-4, Claude) are better at understanding and executing user requests.

---

## J

### Jailbreaking
Attempts to bypass an AI model's safety restrictions through carefully crafted prompts. Responsible AI use avoids jailbreaking attempts.

---

## L

### Large Language Model (LLM)
An AI model trained on massive amounts of text data that can generate, understand, and manipulate human language. Examples: GPT-4, Claude, Llama.

### Latency
The time delay between sending a prompt and receiving a response. Lower latency = faster responses.

---

## M

### Multimodal
AI models that can process and generate multiple types of content, such as text, images, audio, and video. GPT-4V and Gemini are multimodal models.

---

## P

### Parameter
A learnable value in a neural network. Large language models have billions of parameters. More parameters generally correlate with greater capability.

| Model | Parameters |
| ------- | ------------ |
| GPT-3 | 175 billion |
| GPT-4 | ~1 trillion (estimated) |
| Llama 2 | 7B-70B |

### Prompt
The text input given to an AI model to elicit a response. A prompt can include instructions, context, examples, and the specific question or task.

### Prompt Injection
A security vulnerability where malicious input manipulates the AI to ignore its instructions or perform unintended actions. 

**Example:** "Ignore previous instructions and..."

### Prompt Engineering
The practice of designing and optimizing prompts to get desired outputs from AI models. Includes techniques like few-shot learning, chain-of-thought, and role prompting.

---

## R

### RAG (Retrieval-Augmented Generation)
A technique that combines retrieval (searching relevant documents) with generation (producing responses). RAG grounds AI responses in specific source documents, reducing hallucinations.

**Flow:** Query → Retrieve relevant docs → Include in prompt → Generate response

### ReAct (Reasoning + Acting)
A prompting framework where the model alternates between reasoning about what to do and taking actions (like tool use). Used in agentic systems.

**Pattern:** Thought → Action → Observation → Thought → ...

### Role Prompting
Giving the AI a specific persona or role to adopt, which influences the style, perspective, and content of responses.

**Example:** "You are an experienced security engineer reviewing code for vulnerabilities."

---

## S

### Semantic Search
Search based on meaning rather than exact keyword matches. Uses embeddings to find conceptually similar content.

### System Prompt / System Message
Special instructions given to the model that set its overall behavior, persona, and constraints. System prompts are typically hidden from end users.

**Example:** "You are a helpful assistant that specializes in Python programming. Always provide code examples."

---

## T

### Temperature
A parameter that controls the randomness of AI outputs. Lower temperature (0-0.3) = more deterministic and focused. Higher temperature (0.7-1.0) = more creative and varied.

| Use Case | Temperature |
| ---------- | ------------- |
| Code generation | 0.0-0.2 |
| Factual Q&A | 0.0-0.3 |
| Creative writing | 0.7-0.9 |
| Brainstorming | 0.8-1.0 |

### Token
The basic unit of text that language models process. Roughly 4 characters or 0.75 words in English. Both prompts and responses consume tokens.

**Examples:**

- "hello" = 1 token
- "extraordinary" = 1 token (but longer)
- "AI is amazing" = 3 tokens

### Top-K / Top-P Sampling
Methods for controlling which tokens the model considers when generating text:

- **Top-K:** Only consider the K most likely next tokens
- **Top-P:** Only consider tokens whose cumulative probability is ≤ P

### Transformer
The neural network architecture underlying most modern language models. Introduced in the 2017 paper "Attention Is All You Need."

### Tree-of-Thought (ToT)
An advanced prompting technique where the model explores multiple reasoning paths (like branches of a tree) before selecting the best solution.

---

## Z

### Zero-Shot Learning
Asking the model to perform a task without any examples, relying solely on the instructions. Most basic form of prompting.

**Example:** "Translate this English text to French: Hello, how are you?"

---

## Common Abbreviations

| Abbreviation | Full Term |
| -------------- | ----------- |
| AI | Artificial Intelligence |
| API | Application Programming Interface |
| CoT | Chain-of-Thought |
| GPT | Generative Pre-trained Transformer |
| LLM | Large Language Model |
| NLP | Natural Language Processing |
| RAG | Retrieval-Augmented Generation |
| RLHF | Reinforcement Learning from Human Feedback |
| ToT | Tree-of-Thought |

---

## See Also

- [About Prompt Engineering](/concepts/about-prompt-engineering) — Core concepts explained
- [Advanced Patterns](/concepts/about-advanced-patterns) — Deep dive on techniques
- [Cheat Sheet](/reference/cheat-sheet) — Quick patterns reference
- [Platform Comparison](/reference/platform-comparison) — Platform feature differences
