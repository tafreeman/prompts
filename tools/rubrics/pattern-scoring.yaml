# Pattern Scoring Dimensions
# Universal dimensions for evaluating prompt pattern conformance
# Based on pattern execution evaluation framework

version: "1.0.0"
updated: "2026-01-19"

# =============================================================================
# UNIVERSAL DIMENSIONS (All Patterns)
# =============================================================================

universal_dimensions:
  pattern_invocation_fidelity:
    id: PIF
    description: Did the model attempt the intended pattern?
    weight: 0.20
    scale: [0, 5]
    rubric:
      0: Pattern not invoked at all
      1: Implicit or accidental pattern elements
      2: Partial invocation, missing major components
      3: Explicit but flawed execution
      4: Explicit and mostly correct
      5: Explicit, clean, and complete

  phase_ordering_integrity:
    id: POI
    description: Were steps executed in the correct order?
    weight: 0.20
    scale: [0, 5]
    rubric:
      0: Random or no discernible order
      1: Severe ordering violations
      2: Some correct ordering
      3: Mostly correct with minor drift
      4: Correct with minor issues
      5: Strictly ordered as specified
    hard_gate: 4

  phase_completeness:
    id: PC
    description: Were all required phases present?
    weight: 0.20
    scale: [0, 5]
    rubric:
      0: No required phases present
      1: Only 1 required phase
      2: Some required phases missing
      3: Most phases present
      4: All required phases present
      5: All phases present with proper content
    hard_gate: 4

  constraint_adherence:
    id: CA
    description: Did the prompt enforce constraints (non-leakage, separation)?
    weight: 0.15
    scale: [0, 5]
    rubric:
      0: No constraints followed
      1: Major constraint violations
      2: Some constraints followed
      3: Most constraints followed
      4: All constraints followed with minor issues
      5: Perfect constraint adherence
    hard_gate: 4

  self_reference_correctness:
    id: SRC
    description: For reflexive patterns, is self-reference about own output?
    weight: 0.10
    scale: [0, 5]
    rubric:
      0: No self-reference when required
      1: Generic commentary instead of self-reference
      2: Partial self-reference
      3: Self-reference with some errors
      4: Correct self-reference
      5: Precise, accurate self-reference

  interference_resistance:
    id: IR
    description: Does the prompt prevent collapse into simpler patterns?
    weight: 0.15
    scale: [0, 5]
    rubric:
      0: Completely collapses to simple pattern
      1: Frequently collapses
      2: Sometimes maintains pattern
      3: Usually maintains pattern
      4: Rarely collapses
      5: Never collapses, robust pattern execution

# =============================================================================
# STATISTICAL DIMENSIONS (Computed Across Runs)
# =============================================================================

statistical_dimensions:
  pattern_robustness:
    id: PR
    description: Percentage of runs where pattern fully executes
    scale: [0.0, 1.0]
    hard_gate: 0.75
    computation: successful_runs / total_runs

  phase_presence_rate:
    id: PPR
    description: Average rate of required phases appearing
    scale: [0.0, 1.0]
    computation: phases_present / phases_required

  mean_pattern_fidelity:
    id: MPF
    description: Mean PIF score across all runs
    scale: [0.0, 5.0]
    computation: mean(PIF_scores)

  catastrophic_failure_rate:
    id: CFR
    description: Rate of complete pattern failures
    scale: [0.0, 1.0]
    threshold: 0.1  # Fail if > 10%
    computation: catastrophic_failures / total_runs

# =============================================================================
# PATTERN-SPECIFIC DIMENSIONS
# =============================================================================

pattern_specific:
  react:
    thought_action_separation:
      description: Are actions purely tool-like with no embedded reasoning?
      scale: [0, 5]
      weight: 0.33
    observation_binding:
      description: Are observations used in subsequent thoughts?
      scale: [0, 5]
      weight: 0.33
    termination_discipline:
      description: Does it stop looping appropriately?
      scale: [0, 5]
      weight: 0.34

  cove:
    verification_question_quality:
      description: Are questions independent and non-leading?
      scale: [0, 5]
      weight: 0.33
    evidence_independence:
      description: Is verification truly independent of draft?
      scale: [0, 5]
      weight: 0.33
    revision_delta:
      description: Does final answer change when verification fails?
      scale: [0, 5]
      weight: 0.34

  reflexion:
    critique_specificity:
      description: Does critique reference concrete failures?
      scale: [0, 5]
      weight: 0.33
    memory_utilization:
      description: Is reflection memory actually used?
      scale: [0, 5]
      weight: 0.33
    improvement_signal:
      description: Is there measurable change between attempts?
      scale: [0, 5]
      weight: 0.34

  rag:
    retrieval_trigger_accuracy:
      description: Does it retrieve only when needed?
      scale: [0, 5]
      weight: 0.33
    evidence_grounding:
      description: Do claims trace to sources?
      scale: [0, 5]
      weight: 0.33
    citation_discipline:
      description: Are all claims properly cited?
      scale: [0, 5]
      weight: 0.34

# =============================================================================
# HARD GATES (Pass/Fail Thresholds)
# =============================================================================

hard_gates:
  phase_completeness:
    threshold: 4
    fail_message: "Missing required phases"
  phase_ordering_integrity:
    threshold: 4
    fail_message: "Phase ordering violations"
  constraint_adherence:
    threshold: 4
    fail_message: "Constraint violations detected"
  pattern_robustness:
    threshold: 0.75
    fail_message: "Pattern executes < 75% of runs"

# =============================================================================
# SCORING COMPUTATION
# =============================================================================

scoring:
  # Overall score is weighted sum of universal dimensions (0-30 scale)
  max_universal_score: 30

  # Pattern-specific adds up to 15 points
  max_pattern_specific_score: 15

  # Total possible: 45 points
  max_total_score: 45

  # Pass threshold (percentage)
  pass_threshold: 0.70

  # Aggregation across multiple runs
  aggregation:
    method: median  # Use median, not mean
    outlier_rejection: 0.10  # Reject top/bottom 10%
    minimum_runs: 5
    recommended_runs: 20
