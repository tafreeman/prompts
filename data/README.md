# Data

This directory contains structured data files that define the taxonomy, configuration, and metadata for the Enterprise AI Prompt Library. These files drive validation, filtering, learning paths, and database operations.

## ğŸ“ Directory Structure

```text
data/
â”œâ”€â”€ db/                    # ğŸ“Š Database storage files
â”‚   â”œâ”€â”€ evaluations.json   # Prompt evaluation results
â”‚   â”œâ”€â”€ prompts.json       # Prompt metadata index
â”‚   â””â”€â”€ rubrics.json       # Evaluation rubrics
â”œâ”€â”€ learning-tracks/       # ğŸ“ Structured learning paths
â”‚   â”œâ”€â”€ architect-depth.yml
â”‚   â”œâ”€â”€ engineer-quickstart.yml
â”‚   â””â”€â”€ functional-productivity.yml
â”œâ”€â”€ audiences.yml          # ğŸ‘¥ Target user personas
â”œâ”€â”€ platforms.yml          # ğŸ–¥ï¸  AI platform definitions
â””â”€â”€ topics.yml            # ğŸ·ï¸  Topic taxonomy
```

## ğŸ“Š Core Data Files

### audiences.yml

Defines target user personas and their typical needs.

**Purpose**: Maps prompts to specific user roles for better discoverability.

**Schema**:

```yaml
audiences:

  - id: junior-engineer

    name: Junior Engineer
    description: Engineers with 0-2 years of experience
    typical_needs:

      - Copy-paste templates
      - Clear step-by-step instructions

    learning_track: engineer-quickstart
```

**Supported Audiences**:

- `junior-engineer`: 0-2 years experience, needs templates
- `senior-engineer`: 3+ years experience, needs customizable patterns
- `solution-architect`: System design and architecture focus
- `qa-engineer`: Testing and quality assurance
- `business-analyst`: Requirements and documentation
- `project-manager`: Status reports and risk assessment
- `functional-team`: Non-technical productivity users

**Usage**: Referenced in prompt frontmatter via `audience` field.

### platforms.yml

Defines AI platforms and their capabilities.

**Purpose**: Ensures prompts specify compatible platforms for optimal results.

**Example Platforms**:

- `github-copilot`: GitHub Copilot (Chat, Edits, Agents)
- `claude`: Anthropic Claude (3.x, Sonnet, Opus)
- `chatgpt`: OpenAI ChatGPT (GPT-4, GPT-4o)
- `m365-copilot`: Microsoft 365 Copilot
- `windows-copilot`: Windows Copilot

**Usage**: Referenced in prompt frontmatter via `platforms` field.

### topics.yml

Defines the topic taxonomy for categorizing and filtering prompts.

**Purpose**: Enables tag-based search and filtering across the library.

**Schema**:

```yaml
topics:

  - id: code-generation

    name: Code Generation
    description: Prompts for generating code, functions, classes
```

**Supported Topics**:

- `code-generation`: Generate code, functions, classes
- `debugging`: Identify and fix bugs
- `refactoring`: Improve code structure and quality
- `testing`: Generate tests and test strategies
- `documentation`: Write docs, comments, READMEs
- `analysis`: Data analysis and insights
- `governance`: Compliance, risk, and audit
- `business`: Business documents and communications
- `productivity`: Workflow efficiency
- `architecture`: System design decisions
- `security`: Security review and best practices
- `performance`: Performance optimization

**Usage**: Referenced in prompt frontmatter via `topics` or `tags` field.

## ğŸ“ Learning Tracks

Curated learning paths for different user personas, defined in `learning-tracks/`.

### architect-depth.yml

**Audience**: Solution architects, tech leads, senior engineers  
**Focus**: System design, architecture patterns, trade-off analysis  
**Duration**: Advanced, self-paced

**Contents**:

- Architecture decision records
- System design prompts
- Trade-off analysis frameworks
- Enterprise patterns

### engineer-quickstart.yml

**Audience**: Junior and senior engineers, QA engineers  
**Focus**: Code generation, testing, debugging, refactoring  
**Duration**: Beginner to intermediate, 2-4 hours

**Contents**:

- Your first prompt (15 min)
- Code generation basics
- Test-driven prompting
- Debugging patterns

### functional-productivity.yml

**Audience**: Business analysts, project managers, functional teams  
**Focus**: Document creation, email drafting, data analysis  
**Duration**: Beginner-friendly, 1-2 hours

**Contents**:

- Document generation
- Meeting summaries
- Status reports
- Data insights

## ğŸ“Š Database Storage (db/)

JSON-based storage for evaluation results and metadata.

### evaluations.json

Stores evaluation results for all prompts.

**Schema**:

```json
{
  "prompt_id": "developers/code-generation",
  "scores": {
    "clarity": 85,
    "structure": 90,
    "usefulness": 88
  },
  "tier": 1,
  "timestamp": "2025-11-30T12:00:00Z"
}
```

**Generated By**: `prompttools evaluate` CLI command

### prompts.json

Index of all prompts with metadata for fast lookup.

**Schema**:

```json
{
  "id": "developers/code-generation",
  "title": "Generate Python Function",
  "category": "developers",
  "tags": ["code-generation", "python"],
  "audience": ["junior-engineer", "senior-engineer"],
  "platforms": ["github-copilot", "claude", "chatgpt"],
  "path": "prompts/developers/code-generation.md"
}
```

**Generated By**: Prompt indexer during validation

### rubrics.json

Evaluation rubrics and scoring criteria.

**Schema**:

```json
{
  "clarity": {
    "description": "How clear and understandable is the prompt?",
    "weight": 0.25,
    "criteria": [
      "Unambiguous language",
      "Clear objectives",
      "Minimal jargon"
    ]
  }
}
```

**Used By**: `prompttools evaluate` for scoring prompts

## ğŸ”§ Using Data Files

### For Contributors

When adding a new prompt, reference valid values from these files:

```yaml
---
title: "My New Prompt"
audience:

  - junior-engineer      # Must exist in audiences.yml

platforms:

  - github-copilot       # Must exist in platforms.yml
  - claude

tags:

  - code-generation      # Must exist in topics.yml

---
```

### For Validation

The validation tool checks prompts against these schemas:

```bash
# Validate all prompts against data schemas
prompttools validate prompts/

# Check for invalid audience values
grep -r "audience:" prompts/ | # Check against audiences.yml
```

### For Learning Path Navigation

Use learning tracks to guide users:

```python
# Load learning track
import yaml
with open("data/learning-tracks/engineer-quickstart.yml") as f:
    track = yaml.safe_load(f)

# Display recommended sequence
for module in track["modules"]:
    print(f"- {module['title']} ({module['duration']})")
```

## ğŸ“ Extending the Data Schema

### Adding a New Audience

1. Edit `audiences.yml`:

   ```yaml

   - id: new-role

     name: New Role
     description: Description of the role
     typical_needs:

       - Need 1
       - Need 2

     learning_track: appropriate-track
   ```

2. Update relevant learning tracks if needed

3. Commit and push changes

### Adding a New Topic

1. Edit `topics.yml`:

   ```yaml

   - id: new-topic

     name: New Topic
     description: What this topic covers
   ```

2. Tag existing prompts if applicable

3. Update documentation to reference the new topic

### Adding a New Platform

1. Edit `platforms.yml`:

   ```yaml

   - id: new-platform

     name: New Platform
     description: Platform description
     capabilities:

       - Feature 1
       - Feature 2

   ```

2. Test prompts on the new platform

3. Update prompt frontmatter with `platforms: [new-platform]`

## ğŸ”„ Data Maintenance

### Update Frequency

- **audiences.yml**: Updated when new personas are identified (quarterly)
- **platforms.yml**: Updated when new AI platforms are added (as needed)
- **topics.yml**: Updated when new categories emerge (quarterly)
- **db/*.json**: Updated automatically during evaluation runs

### Validation

All data files are validated on commit:

```bash
# Validate YAML syntax
yamllint data/*.yml data/learning-tracks/*.yml

# Validate JSON syntax
jq . data/db/*.json

# Validate schema consistency
python tools/validate_data.py
```

## ğŸ“Š Data-Driven Features

These data files enable several key features:

1. **Smart Filtering**: Filter prompts by audience, platform, or topic
2. **Learning Paths**: Guided sequences for different personas
3. **Validation**: Ensure prompts meet quality standards
4. **Analytics**: Track prompt usage and effectiveness
5. **Recommendations**: Suggest prompts based on user context

## ğŸ¤ Contributing

When contributing data changes:

1. **Maintain backward compatibility**: Don't remove existing IDs
2. **Add, don't delete**: Deprecate old values, don't remove them
3. **Document changes**: Update this README with new fields
4. **Test validation**: Ensure existing prompts still validate

See [CONTRIBUTING.md](../CONTRIBUTING.md) for detailed guidelines.

## ğŸ“š Related Resources

- **[Docs](../docs/)**: Documentation and guides
- **[Prompt Library](../prompts/)**: The actual prompt collection
- **[Tools](../tools/)**: CLI and validation utilities
- **[Prompttools](../prompttools/)**: Evaluation and validation toolkit

## ğŸ“„ License

All data files are licensed under [MIT License](../LICENSE).

---

**Questions about data schemas?** Open an issue in the [main repository](https://github.com/tafreeman/prompts).
