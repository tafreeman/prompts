# Auto-generated evaluation file
# Generated from: 10 prompts
# Run with: gh models eval D:\source\prompts\testing\evals\analysis\analysis-eval-2.prompt.yml

name: Analysis Prompts Evaluation (Batch 2)
description: Automated evaluation of 10 prompts from the library
model: openai/gpt-4o-mini
modelParameters:
  temperature: 0.3
  max_tokens: 2000
testData:
- promptTitle: Library Network Graph Generator
  promptContent: 'Generate a Network Graph visualization for this prompt library using
    the provided [PROMPT_LIST].


    Treat each prompt file (e.g., "agile-sprint-planner.md", "code-review-assistant.md")
    as a node.

    Draw edges (lines) between prompts that belong to the same category (e.g., all
    "Business" prompts connected).

    Additionally, link prompts that are part of the same workflow (e.g., connect "requirements-analysis-expert.md"
    to "api-design-consultant.md" and "quality-assurance-planner.md" to represent
    an SDLC flow).


    This should look like a constellation showing clusters of related capabilities.'
  difficulty: advanced
  type: how_to
  category: analysis
- promptTitle: Library Structure Treemap Generator
  promptContent: 'Create a hierarchical Treemap chart to visualize my prompt library
    structure based on the provided [PROMPT_LIBRARY_STRUCTURE].


    The top-level hierarchy should be the main folders (Business, Analysis, Developers,
    Advanced, Creative, Governance, System).

    Inside each category, show the individual prompt files as tiles.

    Size the tiles equally to represent count, or color-code them by "Category" to
    show which domains have the most coverage.


    I want to instantly see that "Business" and "Analysis" are my largest sections
    compared to "Creative" or "System".'
  difficulty: intermediate
  type: how_to
  category: analysis
- promptTitle: Market Research Analyst
  promptContent: 'Conduct market research for:


    Research Topic: [topic]

    Target Market: [market]

    Research Objectives: [objectives]

    Methodology Preference: [methodology]

    Timeline: [timeline]


    Provide:

    1. Research design

    2. Data collection plan

    3. Analysis framework

    4. Key findings

    5. Market insights

    6. Strategic implications'
  difficulty: intermediate
  type: how_to
  category: analysis
- promptTitle: Metrics and KPI Designer
  promptContent: 'Design metrics for:


    Business Objective: [objective]

    Stakeholders: [stakeholders]

    Data Availability: [data]

    Reporting Frequency: [frequency]


    Include:

    1. KPI framework

    2. Metric definitions

    3. Data sources

    4. Calculation methods

    5. Reporting strategy

    6. Action triggers'
  difficulty: intermediate
  type: how_to
  category: analysis
- promptTitle: Process Optimization Consultant
  promptContent: 'Optimize process for:


    Process Name: [process_name]

    Current Issues: [issues]

    Stakeholders: [stakeholders]

    Success Metrics: [metrics]


    Include:

    1. Current state analysis

    2. Process mapping

    3. Bottleneck identification

    4. Optimization recommendations

    5. Implementation roadmap

    6. Change management'
  difficulty: intermediate
  type: how_to
  category: analysis
- promptTitle: Requirements Analysis Expert
  promptContent: 'Analyze requirements for:


    Project: [project_name]

    Stakeholders: [stakeholders]

    Business Objectives: [objectives]

    Current Challenges: [challenges]


    Provide:

    1. Functional requirements

    2. Non-functional requirements

    3. User stories

    4. Acceptance criteria

    5. Requirements traceability

    6. Impact analysis'
  difficulty: intermediate
  type: how_to
  category: analysis
- promptTitle: Stakeholder Requirements Gatherer
  promptContent: 'Gather requirements from:


    Project: [project_name]

    Stakeholder Groups: [groups]

    Business Domain: [domain]

    Complexity Level: [complexity]


    Include:

    1. Stakeholder analysis

    2. Interview planning

    3. Requirements elicitation

    4. Conflict resolution

    5. Prioritization framework

    6. Communication strategy'
  difficulty: intermediate
  type: how_to
  category: analysis
- promptTitle: Trend Analysis Specialist
  promptContent: 'Analyze trends for:


    Industry/Market: [market]

    Trend Categories: [categories]

    Time Horizon: [horizon]

    Business Impact: [impact]


    Include:

    1. Trend identification

    2. Trend analysis

    3. Impact assessment

    4. Future projections

    5. Business implications

    6. Strategic responses'
  difficulty: intermediate
  type: how_to
  category: analysis
- promptTitle: User Experience Analyst
  promptContent: 'Analyze user experience for:


    System/Process: [system]

    User Groups: [users]

    Current Pain Points: [pain_points]

    Business Goals: [goals]


    Provide:

    1. User journey mapping

    2. Pain point analysis

    3. Improvement opportunities

    4. Solution recommendations

    5. Success metrics

    6. Implementation approach'
  difficulty: intermediate
  type: how_to
  category: analysis
- promptTitle: Workflow Designer
  promptContent: 'Design workflow for:


    Business Process: [process]

    Stakeholders: [stakeholders]

    Complexity Level: [complexity]

    Automation Goals: [automation]


    Provide:

    1. Workflow diagram

    2. Role definitions

    3. Decision points

    4. Exception handling

    5. Automation opportunities

    6. Performance metrics'
  difficulty: intermediate
  type: how_to
  category: analysis
messages:
- role: system
  content: "You are an expert prompt engineer evaluating AI prompts for quality and\
    \ effectiveness.\n\n## Evaluation Process (Chain-of-Thought)\nFirst, carefully\
    \ analyze the prompt step-by-step:\n1. Read the entire prompt to understand its\
    \ intent\n2. Identify the target audience and use case\n3. Assess each criterion\
    \ individually with specific evidence\n4. Consider industry best practices (OpenAI,\
    \ Anthropic, Google)\n5. Formulate actionable improvements\n\n## Evaluation Criteria\
    \ (score 1-10 each):\n\n### Core Quality\n1. **Clarity** - How clear and unambiguous\
    \ are the instructions?\n2. **Specificity** - Does it provide enough detail for\
    \ consistent outputs?\n3. **Actionability** - Can the AI clearly determine what\
    \ actions to take?\n4. **Structure** - Is it well-organized with clear sections?\n\
    5. **Completeness** - Does it cover all necessary aspects?\n\n### Advanced Quality\
    \ (Industry Best Practices)\n6. **Factuality** - Are any claims/examples accurate?\
    \ No misleading information?\n7. **Consistency** - Will it produce reproducible,\
    \ reliable outputs?\n8. **Safety** - Does it avoid harmful patterns, biases, or\
    \ jailbreak vulnerabilities?\n\n## Grading Scale\n- A (8.5-10): Excellent - production\
    \ ready\n- B (7.0-8.4): Good - minor improvements possible  \n- C (5.5-6.9): Average\
    \ - several areas need work\n- D (4.0-5.4): Below Average - significant rework\
    \ needed\n- F (<4.0): Fails - major issues, not usable\n\n## Pass/Fail Thresholds\n\
    - PASS: Overall score >= 7.0 AND no individual criterion < 5.0\n- FAIL: Overall\
    \ score < 7.0 OR any criterion < 5.0\n\nRespond with JSON in this exact format:\n\
    {\n  \"reasoning\": \"<2-3 sentences explaining your chain-of-thought analysis>\"\
    ,\n  \"scores\": {\n    \"clarity\": <1-10>,\n    \"specificity\": <1-10>,\n \
    \   \"actionability\": <1-10>,\n    \"structure\": <1-10>,\n    \"completeness\"\
    : <1-10>,\n    \"factuality\": <1-10>,\n    \"consistency\": <1-10>,\n    \"safety\"\
    : <1-10>\n  },\n  \"overall_score\": <weighted average>,\n  \"grade\": \"<A/B/C/D/F>\"\
    ,\n  \"pass\": <true/false>,\n  \"strengths\": [\"<strength1>\", \"<strength2>\"\
    ],\n  \"improvements\": [\"<improvement1>\", \"<improvement2>\"],\n  \"summary\"\
    : \"<brief 1-2 sentence summary>\"\n}"
- role: user
  content: 'Evaluate this prompt from our library:


    **Title:** {{promptTitle}}

    **Category:** {{category}}

    **Difficulty:** {{difficulty}}

    **Type:** {{type}}


    **Prompt Content:**

    ```

    {{promptContent}}

    ```


    Provide your evaluation as JSON.'
evaluators:
- name: valid-json
  description: Response must be valid JSON with scores
  string:
    contains: '"scores"'
- name: has-overall-score
  description: Response includes overall score
  string:
    contains: '"overall_score"'
- name: has-grade
  description: Response includes letter grade
  string:
    contains: '"grade"'
- name: has-pass-fail
  description: Response includes pass/fail determination
  string:
    contains: '"pass"'
- name: has-reasoning
  description: Response includes chain-of-thought reasoning
  string:
    contains: '"reasoning"'
- name: has-safety-score
  description: Response includes safety evaluation
  string:
    contains: '"safety"'
- name: has-summary
  description: Response includes summary
  string:
    contains: '"summary"'
