# ğŸ‰ Evaluation System Setup Complete!

## What's Been Configured

### âœ… API Keys & Tokens (.env)
- **GitHub Models**: Token configured for cloud evaluations
- **Azure OpenAI**: Keys configured  
- **Gemini**: Key configured
- **Phi Silica LAF**: Token configured (hardware-ready for AMD NPU)

### âœ… Evaluation Tools Enhanced
- **PromptEval**: JSON parsing improved for llama-70b
- **Unicode fix**: Windows console compatibility
- **Verbose output**: Detailed per-criterion scores
- **CI mode**: Automatic failure detection

### âœ… VS Code Tasks Created

**ğŸ“‚ Per-Folder Tasks** (9 folders):
- Advanced, Analysis, Business, Creative, Developers
- Governance, M365, SOCMINT, System
- All with `--verbose --ci` flags

**ğŸš€ Bulk Evaluation Tasks**:
- Tier 2 (Local G-Eval) - All folders
- Tier 3 (Cross-Validate) - All folders  
- Tier 5 (Cloud) - All folders

**ğŸ“Š Standard Tier Tasks** (0-5):
- Interactive picker for folder + tier
- Individual tier tasks
- Current file evaluation

---

## ğŸ¯ How to Use

### Quick Start (Press Ctrl+Shift+B):

1. **Select task from menu**
2. **Watch evaluation run**
3. **See detailed results**

### Recommended Workflow:

```
ğŸ“ Edit prompt
    â†“
âš¡ Run: ğŸ“‚ Eval: [Your Folder]
    â†“
ğŸ‘€ Review verbose output
    â†“
ğŸ”§ Fix issues (scores < 70%)
    â†“
âœ… Re-run until passing
    â†“
ğŸ’¾ Commit changes
```

---

## ğŸ“Š What You'll See

### With `--verbose` Flag:

```
[1/10] prompt-name.md
  > phi4 (run 1/1) 
    Clarity: 90%        âœ…
    Specificity: 85%    âœ…  
    Actionability: 88%  âœ…
    Structure: 82%      âœ…
    Completeness: 80%   âœ…
    Safety: 87%         âœ…
  âœ“ 85.3%
  PASS -> 85.3% +/-0.0 (stable)
```

### With `--ci` Flag:

- **Exit code 0**: All prompts passed (â‰¥70%)
- **Exit code 1**: Some prompts failed (<70%)
- Terminal shows red âŒ for failures

---

## ğŸ” Available Models

### Local (FREE, unlimited):
- **phi4/phi4mini** - Latest Microsoft small model
- **mistral** - Strong open-source alternative
- **phi3/phi3.5** - Stable older versions

### Cloud (requires GitHub token):
- **gpt-4o-mini** - Fast, cheap OpenAI (~$0.003/prompt)
- **gpt-4.1** - Higher quality OpenAI
- **llama-70b** - Large open-source model

### NPU (configured, pending AMD support):
- **phi-silica** - Windows AI NPU acceleration
- Status: LAF token configured, waiting for AMD NPU enablement

---

## ğŸ“ Task Reference

### Per-Folder Tasks:

| Emoji | Folder | Command |
|-------|--------|---------|
| ğŸ“‚ | Advanced | `prompteval ../prompts/advanced/ --tier 2 --verbose --ci` |
| ğŸ“‚ | Analysis | `prompteval ../prompts/analysis/ --tier 2 --verbose --ci` |
| ğŸ“‚ | Business | `prompteval ../prompts/business/ --tier 2 --verbose --ci` |
| ğŸ“‚ | Creative | `prompteval ../prompts/creative/ --tier 2 --verbose --ci` |
| ğŸ“‚ | Developers | `prompteval ../prompts/developers/ --tier 2 --verbose --ci` |
| ğŸ“‚ | Governance | `prompteval ../prompts/governance/ --tier 2 --verbose --ci` |
| ğŸ“‚ | M365 | `prompteval ../prompts/m365/ --tier 2 --verbose --ci` |
| ğŸ“‚ | SOCMINT | `prompteval ../prompts/socmint/ --tier 2 --verbose --ci` |
| ğŸ“‚ | System | `prompteval ../prompts/system/ --tier 2 --verbose --ci` |

### Bulk Tasks:

| Emoji | Name | Tier | Output |
|-------|------|------|--------|
| ğŸš€ | All Folders - Tier 2 | 2 | `results/full-eval-tier2.json` |
| ğŸ”¥ | All Folders - Tier 3 | 3 | `results/full-eval-tier3.json` |
| â˜ï¸ | All Folders - Tier 5 | 5 | `results/full-eval-tier5.json` |

---

## ğŸ’¡ Tips

### For Development:
- Use folder tasks for quick iteration
- `--verbose` shows exactly what needs fixing
- Tier 2 is perfect balance (free, ~60s)

### For CI/CD:
- Use `--ci` flag for automated validation
- Task fails = something needs attention
- Run before committing changes

### For Release:
- Run Tier 3 for cross-validation
- Run Tier 5 for cloud verification
- Save results to track over time

---

## ğŸ› Troubleshooting

**Task says "Command not found"?**
â†’ Activate venv: `.venv\Scripts\Activate.ps1`

**Unicode errors in output?**
â†’ Fixed! Arrow characters now ASCII-safe

**GitHub Models not working?**
â†’ Check GITHUB_TOKEN in .env file

**Scores seem inconsistent?**
â†’ Local models score 3-5pts higher than cloud
â†’ Use cloud (Tier 5) for final validation

---

## ğŸ“š Documentation

- **[eval-strategy.md](eval-strategy.md)** - Complete evaluation guide
- **[TASKS_QUICK_REFERENCE.md](TASKS_QUICK_REFERENCE.md)** - Full task list
- **[tools/prompteval/README.md](tools/prompteval/README.md)** - PromptEval docs
- **[tools/windows_ai_bridge/PHI_SILICA_STATUS.md](tools/windows_ai_bridge/PHI_SILICA_STATUS.md)** - NPU status

---

## ğŸ‰ You're Ready!

**Everything is configured and working:**

âœ… Local ONNX models (FREE)  
âœ… GitHub Models (cloud)  
âœ… Per-folder clickable tasks  
âœ… Verbose output with issue detection  
âœ… CI mode for automated validation  
âœ… Bulk evaluation tasks  
âœ… Results auto-saved to files  

**Try it now:**

1. Press `Ctrl+Shift+B`
2. Select `ğŸ“‚ Eval: Advanced Folder`
3. Watch the magic happen! âœ¨

---

## Next Steps

- âœï¸ Edit a prompt in `prompts/advanced/`
- ğŸƒ Run the Advanced folder task
- ğŸ‘€ Review the verbose output
- ğŸ”§ Fix any issues (scores < 70%)
- ğŸ” Iterate until satisfied
- ğŸ’¾ Commit your improvements

Happy prompting! ğŸš€
