# Enhanced Metadata Schema for Prompt Templates
# Version 2.0.0
# Last Updated: 2025-11-23

# This schema defines the required and optional metadata fields for all prompt templates
# in the tafreeman/prompts repository.

required_fields:
  - title
  - category
  - difficulty
  - version
  - author
  - last_updated

optional_fields:
  - subcategory
  - technique_type
  - framework_compatibility
  - use_cases
  - performance_metrics
  - dependencies
  - governance
  - testing
  - tags
  - platform

# Field Definitions and Validation Rules

title:
  type: string
  description: "Clear, descriptive title for the prompt template"
  max_length: 100
  pattern: "^[A-Za-z0-9 :.-]+$"

category:
  type: string
  description: "Primary category classification"
  enum:
    - techniques
    - frameworks
    - analysis
    - business
    - creative
    - developers
    - governance
    - m365
    - system
    - advanced

subcategory:
  type: string
  description: "Secondary categorization for better organization"
  examples:
    - reflexion
    - agentic
    - context-optimization
    - multimodal
    - langchain
    - anthropic
    - openai

technique_type:
  type: string
  description: "Specific technique classification"
  enum:
    - self-correction
    - multi-agent
    - tool-use
    - context-compression
    - many-shot-learning
    - retrieval-augmented
    - constitutional-ai
    - function-calling

framework_compatibility:
  type: object
  description: "Compatible AI frameworks and minimum versions"
  properties:
    langchain:
      type: string
      pattern: "^>=?[0-9]+\\.[0-9]+\\.[0-9]+$"
      example: ">=0.1.0"
    anthropic:
      type: string
      pattern: "^>=?[0-9]+\\.[0-9]+\\.[0-9]+$"
      example: ">=0.8.0"
    openai:
      type: string
      pattern: "^>=?[0-9]+\\.[0-9]+\\.[0-9]+$"
      example: ">=1.0.0"
    microsoft:
      type: string
      example: ">=0.5.0"

difficulty:
  type: string
  description: "Complexity level for implementation"
  enum:
    - beginner
    - intermediate
    - advanced
    - expert

use_cases:
  type: array
  description: "Applicable use case scenarios"
  items:
    type: string
  examples:
    - analysis
    - problem-solving
    - code-generation
    - data-extraction
    - content-creation
    - research

performance_metrics:
  type: object
  description: "Expected performance characteristics"
  properties:
    accuracy_improvement:
      type: string
      pattern: "^[0-9]+-[0-9]+%$"
      example: "15-25%"
    latency_impact:
      type: string
      enum: [low, medium, high]
      description: "Impact on response time"
    cost_multiplier:
      type: string
      pattern: "^[0-9]+\\.?[0-9]*-[0-9]+\\.?[0-9]*x$"
      example: "1.2-1.5x"
      description: "Token cost increase factor"

dependencies:
  type: array
  description: "Required base templates or components"
  items:
    type: string
  examples:
    - base-prompt-template
    - evaluation-framework
    - tool-integration

version:
  type: string
  description: "Semantic version number"
  pattern: "^[0-9]+\\.[0-9]+\\.[0-9]+$"
  example: "2.0.0"

author:
  type: string
  description: "Author name or team"
  example: "AI Research Team"

last_updated:
  type: string
  description: "Last modification date (ISO 8601)"
  pattern: "^[0-9]{4}-[0-9]{2}-[0-9]{2}$"
  example: "2025-11-23"

governance:
  type: object
  description: "Enterprise governance and compliance"
  properties:
    data_classification:
      type: string
      enum: [public, internal, confidential, restricted]
      default: internal
    risk_level:
      type: string
      enum: [low, medium, high]
      default: low
    approval_required:
      type: boolean
      default: false
    approved_by:
      type: string
      description: "Approver name (if approval_required is true)"

testing:
  type: object
  description: "Testing and validation status"
  properties:
    benchmark_score:
      type: integer
      minimum: 0
      maximum: 100
      description: "Overall quality score (0-100)"
    validation_status:
      type: string
      enum: [not_tested, in_progress, passed, failed]
      default: not_tested
    last_tested:
      type: string
      pattern: "^[0-9]{4}-[0-9]{2}-[0-9]{2}$"
    test_coverage:
      type: integer
      minimum: 0
      maximum: 100
      description: "Percentage of test cases passed"

tags:
  type: array
  description: "Searchable tags for discovery"
  items:
    type: string
  max_items: 10

platform:
  type: array
  description: "Compatible AI platforms"
  items:
    type: string
    enum:
      - openai
      - anthropic
      - azure-openai
      - google-vertex
      - aws-bedrock
      - huggingface

# Example Complete Metadata Block
example:
  title: "Advanced Code Analysis with Reflexion"
  category: "techniques"
  subcategory: "reflexion"
  technique_type: "self-correction"
  framework_compatibility:
    langchain: ">=0.1.0"
    anthropic: ">=0.8.0"
    openai: ">=1.0.0"
  difficulty: "advanced"
  use_cases:
    - code-generation
    - problem-solving
    - analysis
  performance_metrics:
    accuracy_improvement: "20-30%"
    latency_impact: "medium"
    cost_multiplier: "1.3-1.6x"
  dependencies:
    - base-prompt-template
    - evaluation-framework
  version: "2.1.0"
  author: "AI Research Team"
  last_updated: "2025-11-23"
  governance:
    data_classification: "internal"
    risk_level: "low"
    approval_required: false
  testing:
    benchmark_score: 87
    validation_status: "passed"
    last_tested: "2025-11-23"
    test_coverage: 95
  tags:
    - reflexion
    - code-analysis
    - self-correction
    - iterative-improvement
  platform:
    - openai
    - anthropic
    - azure-openai
