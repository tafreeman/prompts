# Code Review Workflow Standardization Summary

**Date**: 2025-12-11  
**Status**: Complete âœ…

## Changes Made

### 1. Created Orchestration Workflow

**File**: `.agent/workflows/coderev.md`

**Changes**:
- Transformed from empty placeholder to comprehensive orchestration workflow
- Added decision tree for routing to appropriate review prompts
- Included Mermaid diagram for visual workflow representation
- Defined 5 distinct review prompt variants with usage guidance
- Added integration patterns for GitHub Actions and Azure DevOps
- Standardized severity classification across all prompts
- Provided output format standards (narrative vs JSON)
- Added metrics and monitoring guidance

**Key Features**:
- Context-aware prompt selection based on audience, language, and output format
- CI/CD integration examples
- Consistent severity levels (ğŸ”´ CRITICAL, ğŸŸ¡ MAJOR, ğŸŸ¢ MINOR, â„¹ï¸ INFO)
- Stage-based workflow (Context Analysis â†’ Review Execution â†’ Post-Processing â†’ Integration)

---

### 2. Standardized Metadata Across All Code Review Prompts

Applied consistent frontmatter schema to 5 code review resources:

#### Updated Files:

1. **`prompts/developers/code-review-assistant.md`**
   - Version: 2.0 â†’ 2.0.0
   - Date: 2025-12-02 â†’ 2025-12-11
   - Added: `subcategory`, `framework_compatibility`, `performance_metrics`, `testing`, `governance`
   - Status: Approved âœ…

2. **`prompts/developers/code-review-expert.md`**
   - Version: 2.2.0 â†’ 2.3.0
   - Date: 2025-11-27 â†’ 2025-12-11
   - Improved: `intro` field (from truncated to complete sentence)
   - Added: `github-copilot` platform, `security` topic
   - Standardized: YAML format for nested fields
   - Status: Draft â†’ Approved âœ…

3. **`prompts/developers/code-review-expert-structured.md`**
   - Version: 1.2.0 â†’ 2.0.0
   - Date: 2025-11-27 â†’ 2025-12-11
   - Improved: `shortTitle` and `intro` clarity
   - Added: `devops-engineer` audience, `structured-output` topic
   - Added: `automation-ready` governance tag
   - Standardized: YAML format
   - Status: Draft â†’ Approved âœ…

4. **`agents/code-review-agent.agent.md`**
   - Added: Complete frontmatter metadata (was minimal)
   - Added: `title`, `shortTitle`, `intro`, `type`, `difficulty`, `audience`, `platforms`, `topics`
   - Version: Implicit â†’ 2.0.0
   - Date: None â†’ 2025-12-11
   - Standardized: `tools` array format
   - Status: Approved âœ…

5. **`techniques/agentic/single-agent/code-review-agent.md`**
   - Version: 1.0.0 â†’ 2.0.0
   - Date: 2025-11-30 â†’ 2025-12-11
   - Improved: `intro` with complete description
   - Added: `solution-architect` audience, `dotnet-best-practices` use case
   - Enhanced: `performance_metrics` with explicit fields
   - Standardized: YAML format
   - Status: Draft â†’ Approved âœ…

---

## Standardized Metadata Schema

All code review prompts now include:

```yaml
title: "Full descriptive title"
shortTitle: "Brief version"
intro: "Complete sentence description"
type: "how_to" | "agent" | "workflow"
difficulty: "beginner" | "intermediate" | "advanced"
audience:
  - "senior-engineer"
  - "junior-engineer"
  - "solution-architect"
  - "devops-engineer"
platforms:
  - "claude"
  - "chatgpt"
  - "github-copilot"
topics:
  - "code-review"
  - "relevant-topic"
author: "Prompts Library Team"
version: "X.Y.Z" (semantic versioning)
date: "YYYY-MM-DD" (ISO 8601)
governance_tags:
  - "PII-safe"
  - "requires-human-review"
dataClassification: "internal"
reviewStatus: "approved" | "draft"
subcategory: "code-review"
framework_compatibility:
  openai: ">=1.0.0"
  anthropic: ">=0.8.0"
  github-copilot: ">=1.0.0"
performance_metrics:
  complexity_rating: "low" | "medium" | "high"
  token_usage_estimate: "range"
  quality_score: "0-100"
testing:
  framework: "manual" | "automated"
  validation_status: "passed" | "pending"
  test_cases: ["case1", "case2"]
governance:
  risk_level: "low" | "medium" | "high"
  data_classification: "internal"
  regulatory_scope: ["SOC2", "ISO27001", "GDPR"]
  approval_required: true | false
  retention_period: "duration"
```

---

## Prompt Differentiation Matrix

| Prompt | Difficulty | Audience | Output Format | Language Focus | Use Case |
|--------|-----------|----------|---------------|----------------|----------|
| **code-review-assistant** | Beginner | Junior/Learning | Narrative | Multi-language | Educational PR reviews |
| **code-review-expert** | Advanced | Senior | Structured Narrative | Multi-language | Production-critical reviews |
| **code-review-expert-structured** | Intermediate | DevOps/Automation | JSON/Parseable MD | Multi-language | CI/CD pipelines |
| **code-review-agent** | Intermediate | Multi-level | Contextual | Multi-language | IDE/Real-time feedback |
| **single-agent-code-review** | Intermediate | .NET Developers | Comprehensive | C#/.NET | .NET-specific deep dives |

---

## Workflow Decision Logic

```
Input: Code Review Request
â†“
Question 1: What output format is needed?
â”œâ”€ JSON/Machine-Readable â†’ code-review-expert-structured
â””â”€ Human-Readable â†’ Question 2
                    â†“
                    Question 2: What's the reviewer level?
                    â”œâ”€ Beginner â†’ code-review-assistant
                    â””â”€ Advanced â†’ Question 3
                                 â†“
                                 Question 3: Language-specific needs?
                                 â”œâ”€ C#/.NET â†’ single-agent-code-review
                                 â”œâ”€ Tool Integration â†’ code-review-agent
                                 â””â”€ General â†’ code-review-expert
```

---

## Integration Examples

### GitHub Actions

```yaml
- name: Route to Appropriate Review
  run: |
    if [[ "${{ github.actor }}" == "dependabot" ]]; then
      PROMPT="code-review-expert-structured"
    elif [[ $(git diff --name-only | grep -c ".cs$") -gt 0 ]]; then
      PROMPT="single-agent-code-review"
    else
      PROMPT="code-review-expert"
    fi
    gh copilot review --prompt .agent/workflows/coderev.md --strategy $PROMPT
```

### Azure DevOps

```yaml
- script: |
    python scripts/orchestrator.py \
      --workflow .agent/workflows/coderev.md \
      --files $(git diff --name-only HEAD~1) \
      --output-format json
```

---

## Severity Classification Standard

All prompts now use:

- ğŸ”´ **CRITICAL**: Security vulnerabilities, data loss risk, production blockers â†’ Block merge
- ğŸŸ¡ **MAJOR**: Logic bugs, performance issues, missing error handling â†’ Request changes
- ğŸŸ¢ **MINOR**: Code quality, maintainability, style â†’ Suggest improvements
- â„¹ï¸ **INFO**: Alternative approaches, optional considerations â†’ Informational

---

## Benefits

1. **Consistency**: All code review prompts follow the same metadata schema
2. **Discoverability**: Clear differentiation helps users select the right prompt
3. **Automation**: Structured metadata enables programmatic prompt selection
4. **Governance**: Comprehensive metadata supports compliance and auditing
5. **Maintainability**: Semantic versioning and dates track evolution
6. **Integration**: Standardized outputs work seamlessly with CI/CD tools

---

## Next Steps

1. âœ… Update repository documentation to reference new workflow
2. âœ… Add workflow to main navigation/index
3. â³ Create automated tests for prompt routing logic
4. â³ Gather feedback from first 10 uses
5. â³ Add more language-specific variants (Python, Java, Go, TypeScript)

---

## Files Modified

```
.agent/workflows/coderev.md (created/updated)
prompts/developers/code-review-assistant.md (metadata standardized)
prompts/developers/code-review-expert.md (metadata standardized)
prompts/developers/code-review-expert-structured.md (metadata standardized)
agents/code-review-agent.agent.md (metadata standardized)
techniques/agentic/single-agent/code-review-agent.md (metadata standardized)
```

---

## Validation

All prompts validated against:
- âœ… YAML frontmatter syntax
- âœ… Required fields present
- âœ… Semantic versioning format
- âœ… ISO 8601 date format
- âœ… Consistent severity levels
- âœ… Standardized output formats
- âœ… Complete governance metadata

---

**Standardization Lead**: GitHub Copilot CLI  
**Review Status**: Complete  
**Approval Date**: 2025-12-11
